{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": 2,
  "links": [],
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "DS_PROMETHEUS-LOCAL"
      },
      "description": "Replication Lag:\nPanel Opóźnienie replikacji monitoruje różnicę czasową między głównym serwerem bazy (master) a replikami (standby). Niski lag świadczy o wysokiej synchronizacji, co jest kluczowe dla wysokiej dostępności (HA) oraz prawidłowego skalowania odczytów. W przypadku wysokiego opóźnienia (np. >10 sekund) ryzyko niespójności danych wzrasta, co może wpłynąć na jakość obsługi awaryjnej oraz stabilność aplikacji w środowisku produkcyjnym. Grupa wyników według etykiety provider pozwala porównać, jak poszczególne środowiska (np. lokalne, GCP, Azure, AWS) radzą sobie z replikacją.",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 6,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "11.6.0",
      "targets": [
        {
          "editorMode": "code",
          "expr": "max by(provider) (pg_replication_lag{role=\"replica\"})",
          "legendFormat": "Replication Lag – {{provider}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Panel Title",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "DS_PROMETHEUS-LOCAL"
      },
      "description": "WAL Throughput:\nTen panel mierzy intensywność generowania transakcyjnego zapisu w PostgreSQL poprzez śledzenie przyrostu pozycji Write-Ahead Log (WAL). Zapisy WAL są kluczowe dla trwałości transakcji oraz replikacji, a wysoka wartość (wyrażona w MB/s) może wskazywać na intensywne operacje zapisu – potencjalnie stanowiące wąskie gardło I/O. Porównanie metryk między środowiskami pozwala ocenić, które z nich generują więcej WAL, co ma znaczenie przy testach obciążeniowych (np. narzędzia k6).\n\nPending WAL Files:\nPanel ten mierzy przepustowość zapisu transakcyjnego, wyliczając liczbę archiwizowanych segmentów WAL w jednostce czasu (przyrostu liczby segmentów w ciągu 5 minut) przeliczonych na megabajty na sekundę. Wysoki WAL Throughput świadczy o intensywnym obciążeniu operacjami zapisu, co może być istotne przy testach obciążeniowych (np. k6) oraz przy porównaniu środowisk (lokalne, GCP, Azure, AWS).\n\nPending WAL Files:\nPanel ten służy do monitorowania liczby plików WAL, które oczekują na archiwizację. Wzrost tej wartości może świadczyć o tym, że system nie nadąża z przetwarzaniem zapisu WAL (np. z powodu wolniejszego I/O lub problemów konfiguracji archiwizacji). Monitorowanie tej metryki pozwala zapobiec sytuacjom, w których zaległe pliki WAL mogą zapełnić przestrzeń dyskową i wpłynąć negatywnie na wydajność systemu OLTP.",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 5,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "11.6.0",
      "targets": [
        {
          "editorMode": "code",
          "expr": "(\r\n  rate(pg_stat_archiver_archived_count[$graph_interval])\r\n  *\r\n  pg_settings_wal_segment_size_bytes\r\n)\r\n/\r\n(1024*1024)\r\n",
          "legendFormat": "WAL Throughput (MB/s) – {{provider}}",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "DS_PROMETHEUS-LOCAL"
          },
          "editorMode": "code",
          "expr": "sum by(provider) (pg_archiver_pending_wal_count)",
          "hide": false,
          "instant": false,
          "legendFormat": "Pending WAL Files – {{provider}}",
          "range": true,
          "refId": "B"
        }
      ],
      "title": "WAL i zapisy transakcyjne (Write-Ahead Log)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "DS_PROMETHEUS-LOCAL"
      },
      "description": "Opis: Cache hit ratio (stosunek trafień do odwołań do pamięci cache) obrazuje efektywność wykorzystania pamięci przez Postgresa. Im wyższy odsetek trafień, tym więcej operacji odbywa się w RAM, bez konieczności sięgania do dysku – co oznacza niskie opóźnienia. Panel ten mierzy procent odczytów danych z cache (shared buffers) vs. z dysku. Biznesowo, utrzymanie tego wskaźnika blisko 99% jest zazwyczaj celem, bo niski cache hit ratio oznacza częste I/O dyskowe, spowalniające zapytania​. Przy porównaniu różnych środowisk, wskaźnik ten pokaże np. czy w chmurze o słabszej maszynie dochodzi do większych braków w cache (np. z powodu mniejszej pamięci), co objawi się niższym % trafień i większymi opóźnieniami. W razie niskiego hit ratio (<80%) należy rozważyć zwiększenie pamięci przydzielonej bazie lub optymalizację zapytań​\n\nProcentowy udział trafień w cache:\nMetryka pg_stat_database_blks_hit zlicza odczyty bloków z pamięci (cache), a pg_stat_database_blks_read – odczyty bloków z dysku​. Iloraz blks_hit / (blks_hit + blks_read) pomnożony przez 100% daje bieżący poziom trafień cache (cache hit rate).",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 16
      },
      "id": 4,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "11.6.0",
      "targets": [
        {
          "editorMode": "code",
          "exemplar": false,
          "expr": "100 * (\r\n  sum by(provider) (rate(pg_stat_database_blks_hit[$graph_interval]))\r\n  /\r\n  (\r\n    sum by(provider) (rate(pg_stat_database_blks_hit[$graph_interval]))\r\n    +\r\n    sum by(provider) (rate(pg_stat_database_blks_read[$graph_interval]))\r\n  )\r\n)\r\n",
          "instant": false,
          "legendFormat": "Procentowy udział trafień w cache - {{provider}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Współczynnik trafień cache (Cache Hit Ratio)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "DS_PROMETHEUS-LOCAL"
      },
      "description": "Opis: \nPanel Blokady pozwala śledzić sytuacje, w których transakcje wzajemnie się blokują lub czekają na siebie. W praktyce monitoruje się liczbę zablokowanych zapytań oraz ewentualnie czas najdłuższego oczekiwania na blokadę. Te wskaźniki są krytyczne dla utrzymania płynności – jeśli pojawiają się blokady, aplikacja może spowolnić lub nawet dojść do zakleszczeń. Profesjonalni administratorzy monitorują blokady, by szybko reagować na wzajemnie blokujące się transakcje​. W kontekście porównania środowisk, może się okazać że w jednym z nich problemy z blokadami występują częściej (np. z powodu wolniejszego I/O, przez co transakcje dłużej trzymają blokady).\n\nLiczba blokowanych zapytań:\nDzięki temu na wykresie zobaczysz jedną serię dla każdego środowiska (np. local, gcp, itp.).\n\nNajdłuższy czas oczekiwania na blokadę:\nTaki wykres umożliwia szybką ocenę, czy w danym środowisku pojawiają się bardzo długie blokady (co może wskazywać na problemy z konkurencyjnymi zapytaniami lub złym planowaniem transakcji).",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 24
      },
      "id": 3,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "11.6.0",
      "targets": [
        {
          "editorMode": "code",
          "expr": "sum by(provider) (pg_blocked_queries)",
          "legendFormat": "Liczba blokowanych zapytań - {{provider}}",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "DS_PROMETHEUS-LOCAL"
          },
          "editorMode": "code",
          "expr": "max by(provider) (pg_oldest_blocked_age_seconds)",
          "hide": false,
          "instant": false,
          "legendFormat": "Najdłuższy czas oczekiwania na blokadę - {{provider}}",
          "range": true,
          "refId": "B"
        }
      ],
      "title": "Blokady i blokujące zapytania (Locks)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "DS_PROMETHEUS-LOCAL"
      },
      "description": "Opis: Panel Aktywne połączenia pokazuje obciążenie bazy danych pod kątem liczby równoczesnych połączeń i transakcji. W przypadku braku poolera, każda instancja aplikacji Django może otwierać wiele połączeń – kluczowe jest więc monitorowanie, ile połączeń jest aktywnie używanych i jak to się ma do limitu. Jeśli liczba połączeń zbliży się do max_connections, nowe połączenia mogą zostać odrzucone, co spowoduje błędy aplikacji. Monitorując tę metrykę, można również porównać, jak różne środowiska radzą sobie z równoczesnością – np. czy w chmurze X potrzeba więcej wątków obsługi niż w chmurze Y. Jak podkreśla dokumentacja, jeśli mielibyśmy śledzić tylko jedną metrykę sieciową bazy, powinna to być liczba dostępnych połączeń​ – jej spadek oznacza wyczerpywanie zasobów.\n\nAktywne sesje:\nLiczba aktywnych (w danej chwili wykonujących zapytania) połączeń do bazy​. Ta metryka odfiltrowuje połączenia bezczynne i pokazuje tylko te, które aktualnie wykonują pracę. Alternatywnie, można monitorować łączne połączenia (wszystkie stany) używając np. sum(pg_stat_database_numbackends), oraz porównać je do pg_settings_max_connections (maks. dopuszczalnych) – co pozwala śledzić % wykorzystania puli połączeń​.",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": [
          {
            "__systemRef": "hideSeriesFrom",
            "matcher": {
              "id": "byNames",
              "options": {
                "mode": "exclude",
                "names": [
                  "Aktywne sesje - local"
                ],
                "prefix": "All except:",
                "readOnly": true
              }
            },
            "properties": [
              {
                "id": "custom.hideFrom",
                "value": {
                  "legend": false,
                  "tooltip": false,
                  "viz": true
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 32
      },
      "id": 2,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "11.6.0",
      "targets": [
        {
          "editorMode": "code",
          "expr": "max by(provider) (pg_stat_activity_count{state=\"active\", datname=\"postgres\"})",
          "legendFormat": "Aktywne sesje - {{provider}}",
          "range": true,
          "refId": "A"
        }
      ],
      "title": "Aktywne połączenia (Active Connections)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "DS_PROMETHEUS-LOCAL"
      },
      "description": "Transakcje na sekundę (TPS):\nsuma commitów i rollbacków transakcji w czasie (na sekundę) per instancja/środowisko, czyli ogólna liczba transakcji na sekundę.\n\nCzas najdłuższej aktywnej transakcji:\nczas trwania najwolniejszej obecnie aktywnej transakcji (sekundy). Ta metryka pozwala łatwo śledzić, ile trwa najdłuższe bieżące zapytanie​. Jeśli np. przekracza ustalony próg (np. >2s), może to wskazywać na problem wymagający uwagi​.\n\nOpis: Panel Wydajność zapytań mierzy, jak szybko i sprawnie baza danych obsługuje zapytania. Obejmuje to zarówno przepustowość (np. liczba transakcji na sekundę), jak i opóźnienia (czas działania najwolniejszych zapytań). Monitorowanie tych metryk pozwala ocenić, czy aplikacja nadąża z obsługą ruchu oraz czy w danym środowisku pojawiają się wolne zapytania. Na przykład, można śledzić TPS (transactions per second) oraz najdłużej trwającą transakcję. Dlaczego to istotne? Słaba wydajność zapytań wpływa bezpośrednio na czas odpowiedzi aplikacji i doświadczenie użytkownika. W środowisku wielochmurowym te metryki pozwalają porównać, w której infrastrukturze baza działa najszybciej.\n",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisCenteredZero": false,
            "axisColorMode": "text",
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "barWidthFactor": 0.6,
            "drawStyle": "line",
            "fillOpacity": 0,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "auto",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green"
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 40
      },
      "id": 1,
      "options": {
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "hideZeros": false,
          "mode": "single",
          "sort": "none"
        }
      },
      "pluginVersion": "11.6.0",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "DS_PROMETHEUS-LOCAL"
          },
          "editorMode": "code",
          "expr": "sum by(instance, provider) (rate(pg_stat_database_xact_commit[$graph_interval]) + rate(pg_stat_database_xact_rollback[$graph_interval]))",
          "legendFormat": "Transakcje na sekundę (TPS) - {{provider}}",
          "range": true,
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "DS_PROMETHEUS-LOCAL"
          },
          "editorMode": "code",
          "expr": "max by(provider) (pg_stat_activity_max_tx_duration{state=\"active\", datname=\"postgres\"})",
          "hide": false,
          "instant": false,
          "legendFormat": "Czas najdłuższej aktywnej transakcji - {{provider}}",
          "range": true,
          "refId": "B"
        }
      ],
      "title": "Wydajność zapytań (Query Performance)",
      "type": "timeseries"
    }
  ],
  "preload": false,
  "schemaVersion": 41,
  "tags": [],
  "templating": {
    "list": [
      {
        "current": {
          "text": "1h",
          "value": "1h"
        },
        "name": "graph_interval",
        "options": [
          {
            "selected": false,
            "text": "3h",
            "value": "3h"
          },
          {
            "selected": false,
            "text": "2h",
            "value": "2h"
          },
          {
            "selected": true,
            "text": "1h",
            "value": "1h"
          },
          {
            "selected": false,
            "text": "30m",
            "value": "30m"
          },
          {
            "selected": false,
            "text": "15m",
            "value": "15m"
          },
          {
            "selected": false,
            "text": "5m",
            "value": "5m"
          },
          {
            "selected": false,
            "text": "1m",
            "value": "1m"
          }
        ],
        "query": "3h, 2h, 1h, 30m, 15m, 5m, 1m",
        "type": "custom"
      }
    ]
  },
  "time": {
    "from": "now-5m",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "browser",
  "title": "PostgreSQL 16 in Django App Metrics(postgres_exporter)",
  "uid": "eeiwy44ug3n5se",
  "version": 26
}